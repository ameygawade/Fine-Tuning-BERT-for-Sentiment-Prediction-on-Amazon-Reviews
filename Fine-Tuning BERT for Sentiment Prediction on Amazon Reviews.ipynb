{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.27.2)\n",
      "Requirement already satisfied: markdown in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: pydantic in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.9.2)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.0.4)\n",
      "Requirement already satisfied: tabulate in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: werkzeug in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.4)\n",
      "Requirement already satisfied: google-auth in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.35.0)\n",
      "Requirement already satisfied: altair==4.2.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.2.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair==4.2.1) (0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair==4.2.1) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair==4.2.1) (4.23.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair==4.2.1) (2.1.2)\n",
      "Requirement already satisfied: pandas>=0.18 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair==4.2.1) (2.2.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair==4.2.1) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-slugify) (1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth) (4.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair==4.2.1) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair==4.2.1) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair==4.2.1) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair==4.2.1) (0.20.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.18->altair==4.2.1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.18->altair==4.2.1) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyasn1 httpx markdown pydantic pyjwt python-slugify tabulate werkzeug google-auth altair==4.2.1 matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: ftfy in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (6.3.0)\n",
      "Requirement already satisfied: emoji in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.5)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: streamlit in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.39.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from ftfy) (0.2.13)\n",
      "Requirement already satisfied: torch==2.4.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.4.1->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.4.1->torchvision) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.4.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.4.1->torchvision) (2024.9.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (4.2.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.28.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (17.0.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (13.9.2)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<6,>=2.1.5 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.0.3)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\amey9\\appdata\\roaming\\python\\python311\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch==2.4.1->torchvision) (3.0.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\amey9\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers numpy pandas scikit-learn ftfy emoji safetensors tokenizers torchvision torchaudio streamlit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3150, 5)\n",
      "   rating       date         variation  \\\n",
      "0       5  31-Jul-18  Charcoal Fabric    \n",
      "1       5  31-Jul-18  Charcoal Fabric    \n",
      "2       4  31-Jul-18    Walnut Finish    \n",
      "3       5  31-Jul-18  Charcoal Fabric    \n",
      "4       5  31-Jul-18  Charcoal Fabric    \n",
      "\n",
      "                                    verified_reviews  feedback  \n",
      "0                                      Love my Echo!         1  \n",
      "1                                          Loved it!         1  \n",
      "2  Sometimes while playing a game, you can answer...         1  \n",
      "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
      "4                                              Music         1  \n",
      "            rating     feedback\n",
      "count  3150.000000  3150.000000\n",
      "mean      4.463175     0.918413\n",
      "std       1.068506     0.273778\n",
      "min       1.000000     0.000000\n",
      "25%       4.000000     1.000000\n",
      "50%       5.000000     1.000000\n",
      "75%       5.000000     1.000000\n",
      "max       5.000000     1.000000\n",
      "feedback\n",
      "1    2893\n",
      "0     257\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/output.csv')\n",
    "\n",
    "# Check dimension of the data\n",
    "pprint(df.shape)\n",
    "\n",
    "# Display the first few rows\n",
    "pprint(df.head())\n",
    "\n",
    "# Check columns with numerical values\n",
    "pprint(df.describe())\n",
    "\n",
    "# Check distribution of classes\n",
    "pprint(df['feedback'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ratings distribution for positive feedback:'\n",
      "rating\n",
      "5    2286\n",
      "4     455\n",
      "3     152\n",
      "Name: count, dtype: int64\n",
      "'Ratings distribution for negative feedback:'\n",
      "rating\n",
      "1    161\n",
      "2     96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check rating distribution for positive and negative feedback\n",
    "positive_feedback_ratings = df[df['feedback'] == 1]['rating'].value_counts()\n",
    "negative_feedback_ratings = df[df['feedback'] == 0]['rating'].value_counts()\n",
    "\n",
    "pprint(\"Ratings distribution for positive feedback:\")\n",
    "pprint(positive_feedback_ratings)\n",
    "\n",
    "pprint(\"Ratings distribution for negative feedback:\")\n",
    "pprint(negative_feedback_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying null and empty entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN (null) entries: 1\n",
      "Number of empty/whitespace-only entries: 79\n"
     ]
    }
   ],
   "source": [
    "null_count = df['verified_reviews'].isna().sum()\n",
    "\n",
    "# Count how many entries consist of only whitespace or are empty\n",
    "empty_whitespace_count = df['verified_reviews'].str.match(r'^\\s*$', na=False).sum()\n",
    "\n",
    "# Display the counts\n",
    "print(f\"Number of NaN (null) entries: {null_count}\")\n",
    "print(f\"Number of empty/whitespace-only entries: {empty_whitespace_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of feedback and rating for null entries:\n",
      "feedback  rating\n",
      "0         2         1\n",
      "Name: count, dtype: int64\n",
      "Distribution of feedback and rating for whitespace entries:\n",
      "feedback  rating\n",
      "1         5         40\n",
      "0         1         15\n",
      "1         3         12\n",
      "          4          8\n",
      "0         2          4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with null 'verified_reviews'\n",
    "null_entries = df[df['verified_reviews'].isna()]\n",
    "\n",
    "# Filter rows where 'verified_reviews' consist of only whitespace\n",
    "whitespace_entries = df[df['verified_reviews'].str.match(r'^\\s*$', na=False)]\n",
    "\n",
    "# Check the distribution of 'feedback' and 'rating' for null entries\n",
    "print(\"Distribution of feedback and rating for null entries:\")\n",
    "print(null_entries[['feedback', 'rating']].value_counts())\n",
    "\n",
    "# Check the distribution of 'feedback' and 'rating' for whitespace entries\n",
    "print(\"Distribution of feedback and rating for whitespace entries:\")\n",
    "print(whitespace_entries[['feedback', 'rating']].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with null entries in 'verified_reviews':\n",
      "     rating       date variation verified_reviews  feedback\n",
      "473       2  29-Jun-18     White              NaN         0\n",
      "\"Rows with whitespace entries in 'verified_reviews':\"\n",
      "      rating       date             variation verified_reviews  feedback\n",
      "85         5  30-Jul-18  Heather Gray Fabric                           1\n",
      "183        3  29-Jul-18  Heather Gray Fabric                           1\n",
      "219        5  29-Jul-18     Sandstone Fabric                           1\n",
      "374        1  26-Jul-18                 Black                          0\n",
      "406        1  16-Jul-18                 White                          0\n",
      "...      ...        ...                   ...              ...       ...\n",
      "3114       3  30-Jul-18            Black  Dot                          1\n",
      "3120       5  30-Jul-18            Black  Dot                          1\n",
      "3123       4  30-Jul-18            Black  Dot                          1\n",
      "3126       5  30-Jul-18            Black  Dot                          1\n",
      "3141       3  30-Jul-18            Black  Dot                          1\n",
      "\n",
      "[79 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display rows where 'verified_reviews' is null\n",
    "null_entries = df[df['verified_reviews'].isna()]\n",
    "print(\"Rows with null entries in 'verified_reviews':\")\n",
    "print(null_entries)\n",
    "\n",
    "# Display rows where 'verified_reviews' is null\n",
    "whitespace_entries = df[df['verified_reviews'].str.match(r'^\\s*$',na=False)]\n",
    "pprint(\"Rows with whitespace entries in 'verified_reviews':\")\n",
    "pprint(whitespace_entries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution Summary:\n",
    "    - For null entries:\n",
    "        - There's only 1 entry where feedback is 0 and rating is 2. \n",
    "        - This is a negative feedback review, and since it's only a single entry, removing it might not significantly impact the dataset.\n",
    "    - For whitespace-only entries:\n",
    "        - The majority of these are positive feedback with a rating of 5 (40 instances).\n",
    "        - There are also negative feedback entries with ratings of 1 (15 instances) and a few positive ones with ratings of 3 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing and Empty Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping these entries would ensure that only meaningful data is passed to the model. Since these entries don't provide any valuable text data for sentiment analysis, it might be best to remove them.\n",
    "- This approach will maintain the quality of the dataset and avoid introducing any biases that could come from imputing placeholder values like \"No feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset shape after removing null and whitespace entries: (3070, 5)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with NaN (null) in 'verified_reviews'\n",
    "df = df.dropna(subset=['verified_reviews'])\n",
    "\n",
    "# Remove rows where 'verified_reviews' consist of only whitespace\n",
    "df = df[~df['verified_reviews'].str.match(r'^\\s*$', na=False)]\n",
    "\n",
    "# Check the new shape of the dataset after removing these entries\n",
    "print(f\"New dataset shape after removing null and whitespace entries: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the non-ascii entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-ascii entries: 338\n",
      "percentage of non-ascii entry: 11.0%\n"
     ]
    }
   ],
   "source": [
    "non_ascii_count = df['verified_reviews'].str.contains(r'[^\\x00-\\x7F]', na=False).sum()\n",
    "print(f\"Number of non-ascii entries: {non_ascii_count}\")\n",
    "total_entries = df['verified_reviews'].count()\n",
    "percentage_non_ascii_count = non_ascii_count/total_entries\n",
    "\n",
    "print(f\"percentage of non-ascii entry: {(round(percentage_non_ascii_count,2))*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying and Counting Entries with Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries containing emojis: 29\n",
      "      rating       date                     variation  \\\n",
      "49         3  30-Jul-18              Charcoal Fabric    \n",
      "60         5  30-Jul-18          Heather Gray Fabric    \n",
      "134        5  30-Jul-18              Charcoal Fabric    \n",
      "229        5  29-Jul-18              Charcoal Fabric    \n",
      "447        5  05-Jul-18                         Black   \n",
      "541        5  16-Jun-18                         White   \n",
      "681        3  19-May-18                         Black   \n",
      "744        3  30-Jul-18              Charcoal Fabric    \n",
      "755        5  30-Jul-18          Heather Gray Fabric    \n",
      "829        5  30-Jul-18              Charcoal Fabric    \n",
      "924        5  29-Jul-18              Charcoal Fabric    \n",
      "1101       4  30-Jul-18                   Black  Spot   \n",
      "1160       5  29-Jul-18                   Black  Spot   \n",
      "1237       5  26-Jul-18                   Black  Spot   \n",
      "1238       5  26-Jul-18                   Black  Spot   \n",
      "1351       4  19-Jul-18                   White  Spot   \n",
      "1399       5  15-Jul-18                   Black  Spot   \n",
      "1544       5  30-Jul-18                   Black  Show   \n",
      "1692       5  28-Jul-18                   Black  Show   \n",
      "2012       3  20-Jul-18                   Black  Plus   \n",
      "2044       5  14-Jul-18                   Black  Plus   \n",
      "2253       5  30-Jul-18  Configuration: Fire TV Stick   \n",
      "2274       5  30-Jul-18  Configuration: Fire TV Stick   \n",
      "2314       1  30-Jul-18  Configuration: Fire TV Stick   \n",
      "2343       5  30-Jul-18  Configuration: Fire TV Stick   \n",
      "2345       4  30-Jul-18  Configuration: Fire TV Stick   \n",
      "2436       5  30-Jul-18  Configuration: Fire TV Stick   \n",
      "2678       4  30-Jul-18                    Black  Dot   \n",
      "3029       4  30-Jul-18                    Black  Dot   \n",
      "\n",
      "                                       verified_reviews  feedback  \n",
      "49    No different than Apple. To play a specific li...         1  \n",
      "60                                                    ðŸ˜         1  \n",
      "134                                  So far I like it ðŸ¤“         1  \n",
      "229   Best thing I've invested in in a while thank y...         1  \n",
      "447   Works perfect no wear and tear on the device I...         1  \n",
      "541   Well Iâ€™m a big fan of echoes these ones went I...         1  \n",
      "681   Seems to have trouble hearing me when I say th...         1  \n",
      "744   No different than Apple. To play a specific li...         1  \n",
      "755                                                   ðŸ˜         1  \n",
      "829                                  So far I like it ðŸ¤“         1  \n",
      "924   Best thing I've invested in in a while thank y...         1  \n",
      "1101  It was a gift and the recipient love love love...         1  \n",
      "1160  This is our first step into a smart home. Soon...         1  \n",
      "1237  I am a small business owner with no staff. Wit...         1  \n",
      "1238  Bedroom clock , ask questions,  weather report...         1  \n",
      "1351  The echo spot is really great. I just got it a...         1  \n",
      "1399  Iâ€™m not sure why or how Amazonia asking me abo...         1  \n",
      "1544  Love it! Easy setup and I can â€˜Drop inâ€™ on my ...         1  \n",
      "1692                                                 ðŸ‘ðŸ»         1  \n",
      "2012  I was suppose to get the â€œfreeâ€ lightbulb with...         1  \n",
      "2044         Love, Love, Love my Amazon Echo Plus!!â¤ï¸â¤ï¸         1  \n",
      "2253                                              â­â­â­â­â­         1  \n",
      "2274  My 90 year old Mom LOVES that she can watch th...         1  \n",
      "2314  Ordered 2 on deal day. 1 doesnâ€™t work and 2 nd...         0  \n",
      "2343  This is my 2nd fire TV stick with Alexa I have...         1  \n",
      "2345  It offers hours of entertainment and it was ve...         1  \n",
      "2436                                                 ðŸ˜„ðŸ˜„         1  \n",
      "2678  Alexa is perfect for people like me living alo...         1  \n",
      "3029  Alexa is perfect for people like me living alo...         1  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define a regex pattern that matches emojis\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "    u\"\\U0001F780-\\U0001F7FF\"  # geometric shapes\n",
    "    u\"\\U0001F800-\\U0001F8FF\"  # supplemental arrows\n",
    "    u\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols & pictographs\n",
    "    u\"\\U0001FA00-\\U0001FA6F\"  # chess symbols\n",
    "    u\"\\U0001FA70-\\U0001FAFF\"  # supplemental pictographs\n",
    "    u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
    "    u\"\\U00000280-\\U0000029F\"  # Braille Patterns (sometimes present in encoded text)\n",
    "    u\"\\U00002500-\\U0000257F\"  # Box Drawing (lines and shapes)\n",
    "    u\"\\U0001F910-\\U0001F91F\"  # Supplemental Symbols and pictographs (hand gestures)\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # Additional emoticons (for newer emojis)\n",
    "    u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and pictographs\n",
    "    u\"\\U0001F6C0-\\U0001F6FF\"  # Transport and map symbols\n",
    "    u\"\\U00002B50-\\U00002B55\"  # Additional symbols (stars, etc.)\n",
    "    u\"\\U00002600-\\U000027BF\"  # Miscellaneous Symbols\n",
    "   \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# Identify entries containing emojis\n",
    "emoji_entries = df[df['verified_reviews'].str.contains(emoji_pattern, na=False)]\n",
    "\n",
    "# Count the number of entries with emojis\n",
    "emoji_count = len(emoji_entries)\n",
    "\n",
    "# Display the count and a few examples of entries with emojis\n",
    "print(f\"Number of entries containing emojis: {emoji_count}\")\n",
    "pprint(emoji_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Non-ASCII Characters While Keeping Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                        Love my Echo!\n",
      "1                                            Loved it!\n",
      "2    Sometimes while playing a game, you can answer...\n",
      "3    I have had a lot of fun with this thing. My 4 ...\n",
      "4                                                Music\n",
      "Name: verified_reviews, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import ftfy\n",
    "# Function to clean non-ASCII characters while keeping emojis\n",
    "def clean_non_ascii_keep_emojis(text):\n",
    "    if pd.notnull(text):\n",
    "        # Step 1: Keep emojis and remove non-ASCII characters using the regex\n",
    "        emojis = emoji_pattern.findall(text)\n",
    "        \n",
    "        # Step 2: Fix encoding issues in the text using ftfy\n",
    "        cleaned_text = ftfy.fix_text(text)\n",
    "        \n",
    "        # Step 3: Remove non-ASCII characters (excluding emojis)\n",
    "        cleaned_text_no_nonascii = re.sub(r'[^\\x00-\\x7F]+', '', cleaned_text)\n",
    "        \n",
    "        # Step 4: Re-add emojis at the end if they were removed\n",
    "        return cleaned_text_no_nonascii + ' ' + ''.join(emojis) if emojis else cleaned_text_no_nonascii\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'verified_reviews' column\n",
    "df['verified_reviews'] = df['verified_reviews'].apply(clean_non_ascii_keep_emojis)\n",
    "\n",
    "# Display cleaned entries\n",
    "print(df['verified_reviews'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-ascii entries: 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3070, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_ascii_count = df['verified_reviews'].str.contains(r'[^\\x00-\\x7F]', na=False).sum()\n",
    "print(f\"Number of non-ascii entries: {non_ascii_count}\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of reviews containing emojis: 0.94%\n",
      "Number of reviews containing emojis: 29\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Identify reviews containing emojis\n",
    "emoji_entries = df[df['verified_reviews'].str.contains(emoji_pattern, na=False)]\n",
    "\n",
    "# Calculate the percentage of reviews containing emojis\n",
    "emoji_percentage = len(emoji_entries) / len(df) * 100\n",
    "print(f\"Percentage of reviews containing emojis: {emoji_percentage:.2f}%\")\n",
    "\n",
    "# Check how many reviews contain emojis\n",
    "print(f\"Number of reviews containing emojis: {len(emoji_entries)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the percentage of emoji usage is low, emojis can still carry strong emotional cues (like \"ðŸ˜\" indicating positive sentiment or \"ðŸ˜’\" indicating negative sentiment). These cues are important in interpreting feedback, especially in cases where the text alone might not fully convey the sentiment (e.g., sarcasm or humor).\n",
    "\n",
    "Given this, converting emojis to text descriptions could still be helpful for sentiment interpretation, even though they are infrequent. By converting them, you're making the emotional intent of the review more explicit, which could help the model better understand the feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Emojis to Text Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "# Convert emojis to their textual descriptions\n",
    "def convert_emoji_to_text(text):\n",
    "    if isinstance(text, str):  # Only process if the input is a string\n",
    "        return emoji.demojize(text)\n",
    "    return text  # Return the original value if it's not a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           Love my Echo!\n",
       "1                                               Loved it!\n",
       "2       Sometimes while playing a game, you can answer...\n",
       "3       I have had a lot of fun with this thing. My 4 ...\n",
       "4                                                   Music\n",
       "                              ...                        \n",
       "3145    Perfect for kids, adults and everyone in betwe...\n",
       "3146    Listening to music, searching locations, check...\n",
       "3147    I do love these things, i have them running my...\n",
       "3148    Only complaint I have is that the sound qualit...\n",
       "3149                                                 Good\n",
       "Name: verified_reviews, Length: 3070, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Apply to the 'verified_reviews' column\n",
    "df['verified_reviews'] = df['verified_reviews'].apply(lambda x: convert_emoji_to_text(x))\n",
    "\n",
    "# Check a few entries\n",
    "df['verified_reviews']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-ascii entries: 0\n",
      "0                                        Love my Echo!\n",
      "1                                            Loved it!\n",
      "2    Sometimes while playing a game, you can answer...\n",
      "3    I have had a lot of fun with this thing. My 4 ...\n",
      "4                                                Music\n",
      "Name: verified_reviews, dtype: object\n"
     ]
    }
   ],
   "source": [
    "non_ascii_count = df['verified_reviews'].str.contains(r'[^\\x00-\\x7F]', na=False).sum()\n",
    "print(f\"Number of non-ascii entries: {non_ascii_count}\")\n",
    "\n",
    "ver_review=df['verified_reviews'].head()\n",
    "\n",
    "pprint(ver_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we extract the relevant columns containing the reviews and feedback (labels), and split the data into training and test sets using an 80-20 split. \n",
    "The training set will be used to fit the model, while the test set will be used for evaluation.\n",
    "We also check the distribution of feedback labels to understand the balance between positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 2456 texts, 2456 labels\n",
      "Validation set: 307 texts, 307 labels\n",
      "Test set: 307 texts, 307 labels\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the test data into validation (10%) and test sets (10%)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Extract texts and labels for training, validation, and test sets\n",
    "train_texts = [str(text) for text in train_data['verified_reviews'] if isinstance(text, str)]\n",
    "val_texts = [str(text) for text in val_data['verified_reviews'] if isinstance(text, str)]\n",
    "test_texts = [str(text) for text in test_data['verified_reviews'] if isinstance(text, str)]\n",
    "\n",
    "# Extract labels (feedback) for training, validation, and test sets\n",
    "train_labels = train_data['feedback'].tolist()\n",
    "val_labels = val_data['feedback'].tolist()\n",
    "test_labels = test_data['feedback'].tolist()\n",
    "\n",
    "# Check sizes to ensure labels and texts match\n",
    "print(f\"Training set: {len(train_texts)} texts, {len(train_labels)} labels\")\n",
    "print(f\"Validation set: {len(val_texts)} texts, {len(val_labels)} labels\")\n",
    "print(f\"Test set: {len(test_texts)} texts, {len(test_labels)} labels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tokenization with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean token length: 33.62907166123779\n",
      "Max token length: 637\n",
      "Min token length: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Clean the text to ensure all values are strings\n",
    "train_texts = [str(text) for text in train_data['verified_reviews'] if isinstance(text, str)]\n",
    "val_texts = [str(text) for text in val_data['verified_reviews'] if isinstance(text, str)]\n",
    "test_texts = [str(text) for text in test_data['verified_reviews'] if isinstance(text, str)]\n",
    "\n",
    "# Tokenize without padding and truncation, and do not return tensors\n",
    "def tokenize_and_get_lengths(texts):\n",
    "    tokenized_outputs = tokenizer(\n",
    "        texts,\n",
    "        padding=False,        # Do not pad the sequences\n",
    "        truncation=False,     # Do not truncate the sequences\n",
    "        return_tensors=None,  # Do not return tensors; we only need raw token lengths\n",
    "        max_length=None       # Allow sequences to take their natural length\n",
    "    )\n",
    "    return [len(tokens) for tokens in tokenized_outputs['input_ids']]\n",
    "\n",
    "# Get the token lengths for the training set\n",
    "train_lengths = tokenize_and_get_lengths(train_texts)\n",
    "\n",
    "# Check the statistics (e.g., mean, max, min) of token lengths\n",
    "import numpy as np\n",
    "print(f\"Mean token length: {np.mean(train_lengths)}\")\n",
    "print(f\"Max token length: {np.max(train_lengths)}\")\n",
    "print(f\"Min token length: {np.min(train_lengths)}\")\n",
    "\n",
    "# Optionally, plot the distribution of token lengths\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_lengths, bins=20, edgecolor='black')\n",
    "plt.title('Distribution of Token Lengths in Training Set')\n",
    "plt.xlabel('Token Length')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokenized inputs: 2454\n",
      "Number of labels: 2454\n"
     ]
    }
   ],
   "source": [
    "# Set max_length based on analysis (e.g., 100 or 128)\n",
    "max_length = 100  # Adjust this if needed\n",
    "\n",
    "# Identify reviews longer than 512 tokens\n",
    "def tokenize_and_get_lengths(texts):\n",
    "    tokenized_outputs = tokenizer(\n",
    "        texts,\n",
    "        padding=False,\n",
    "        truncation=False,\n",
    "        return_tensors=None,\n",
    "        max_length=None\n",
    "    )\n",
    "    return [len(tokens) for tokens in tokenized_outputs['input_ids']]\n",
    "\n",
    "# Get token lengths for the training set\n",
    "train_lengths = tokenize_and_get_lengths(train_texts)\n",
    "\n",
    "# Filter out reviews longer than 512 tokens and their corresponding labels\n",
    "filtered_data = [(text, label) for text, length, label in zip(train_texts, train_lengths, train_labels) if length <= 512]\n",
    "\n",
    "# Separate the filtered texts and labels\n",
    "train_data_filtered, train_labels_filtered = zip(*filtered_data)\n",
    "\n",
    "# Proceed with tokenization using max_length = 100 for the filtered data\n",
    "train_encodings = tokenizer(\n",
    "    list(train_data_filtered),  # Convert back to a list\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "val_encodings = tokenizer(\n",
    "    val_texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    test_texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "# Check if the number of tokenized inputs matches the number of filtered labels\n",
    "print(f\"Number of tokenized inputs: {len(train_encodings['input_ids'])}\")\n",
    "print(f\"Number of labels: {len(train_labels_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fine-Tuning BERT for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Trained BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd  # For checking missing values\n",
    "\n",
    "# Load pre-trained BERT model for binary classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data (Already Tokenized in Step 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokenized inputs: 2454\n",
      "Number of labels (filtered): 2454\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PyTorch Dataset class to handle tokenized encodings and labels\n",
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)  # Ensure this matches the number of tokenized inputs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.labels):  # Protect against out-of-bound access\n",
    "            raise IndexError(f\"Index {idx} is out of bounds with size {len(self.labels)}\")\n",
    "        \n",
    "        # Return the tokenized inputs and the labels at index `idx`\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "\n",
    "# Ensure filtered labels are used for the training dataset\n",
    "train_dataset = ReviewDataset(train_encodings, list(train_labels_filtered))  # Use filtered labels\n",
    "test_dataset = ReviewDataset(test_encodings, test_labels)  # No filtering for test\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Check if the number of tokenized inputs matches the number of filtered labels\n",
    "print(f\"Number of tokenized inputs: {len(train_encodings['input_ids'])}\")\n",
    "print(f\"Number of labels (filtered): {len(train_labels_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Convert the class labels to a numpy array\n",
    "classes = np.array([0, 1])\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_labels)\n",
    "\n",
    "# Convert class weights to a tensor and move to device (GPU or CPU)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# Define the optimizer with learning rate and weight decay\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [09:34<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss with class weighting: 0.2492\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [10:15<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss with class weighting: 0.1057\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [10:11<00:00,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss with class weighting: 0.0561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # For progress bar during training\n",
    "\n",
    "def train(model, train_loader, optimizer, device, class_weights):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        # Move inputs and labels to device (GPU or CPU)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass to get model outputs and calculate loss\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Apply class weights to the loss\n",
    "        weighted_loss = loss * class_weights[labels]\n",
    "        loss = weighted_loss.mean()  # Compute average loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        loss.backward()        # Backpropagation\n",
    "        optimizer.step()       # Update model parameters\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Average training loss with class weighting: {avg_loss:.4f}\")\n",
    "\n",
    "# Fine-tune for a few epochs\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    train(model, train_loader, optimizer, device, class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9577\n",
      "F1 Score: 0.9775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for batch in test_loader:\n",
    "            # Move inputs to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass to get predictions\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluate(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(model, test_loader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for batch in test_loader:\n",
    "            # Move inputs to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass to get predictions\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save_pretrained('./bert_sentiment_model_v1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bert_sentiment_tokeniser_v1\\\\tokenizer_config.json',\n",
       " './bert_sentiment_tokeniser_v1\\\\special_tokens_map.json',\n",
       " './bert_sentiment_tokeniser_v1\\\\vocab.txt',\n",
       " './bert_sentiment_tokeniser_v1\\\\added_tokens.json')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('./bert_sentiment_tokeniser_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \"I love this product!\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"This is awesome\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"Not happy with the product.\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"Not happy with it.\"\n",
      "Predicted sentiment: negative\n",
      "\n",
      "Text: \"Not happy with the service.\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"This is not what I expected.\"\n",
      "Predicted sentiment: negative\n",
      "\n",
      "Text: \"Not happy with the color.\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"Not happy with service but product is good\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"The product is great, but the packaging was terrible.\"\n",
      "Predicted sentiment: negative\n",
      "\n",
      "Text: \"I loved the features, but it's way too expensive.\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"This product is lit! :fire:\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"It's dope, can't get enough of it.\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"This is  :fire:\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"This is GOAT:goat:\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"I feel its damn good\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"bad boy song is sounding dope on this :thumbs_up:\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"bad boy song is sounding like samsh hit on this\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"The product arrived on time.\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"It's just okay, nothing special.Yeah, because everyone loves waiting 2 weeks for a delivery...\"\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Text: \"What a innovative product..Thank you amazon for such a good product which doesnt work.\"\n",
      "Predicted sentiment: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Load the saved model\n",
    "model = BertForSequenceClassification.from_pretrained('./bert_sentiment_model_v1')\n",
    "model.eval()\n",
    "\n",
    "# Load the saved tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert_sentiment_tokeniser_v1')\n",
    "\n",
    "# Tokenize new input data\n",
    "new_texts = [\n",
    "    #positive reviews\n",
    "    \"I love this product!\",\n",
    "    \"This is awesome\",\n",
    "    \n",
    "    #negative reviews\n",
    "    \"Not happy with the product.\",\n",
    "    \"Not happy with it.\",\n",
    "\n",
    "    # Negation\n",
    "    \"Not happy with the service.\",  \n",
    "    \"This is not what I expected.\",  \n",
    "    \"Not happy with the color.\",\n",
    "    \"Not happy with service but product is good\",\n",
    "    \n",
    "    # Mixed sentiment\n",
    "    \"The product is great, but the packaging was terrible.\",\n",
    "    \"I loved the features, but it's way too expensive.\",\n",
    "\n",
    "\n",
    "    # Slang and informal\n",
    "    \"This product is lit! ðŸ”¥\",  \n",
    "    \"It's dope, can't get enough of it.\",\n",
    "    \"This is  :fire:\",\n",
    "    \"This is GOATðŸ\",\n",
    "    \"I feel its damn good\",\n",
    "    \"bad boy song is sounding dope on this :thumbs_up:\",\n",
    "    \"bad boy song is sounding like samsh hit on this\",\n",
    "    \n",
    "    # Neutral\n",
    "    \"The product arrived on time.\",  \n",
    "    \"It's just okay, nothing special.\"\n",
    "      \n",
    "    # Sarcastic reviews\n",
    "    \"Yeah, because everyone loves waiting 2 weeks for a delivery...\",\n",
    "    \"What a innovative product..Thank you amazon for such a good product which doesnt work.\"\n",
    "]\n",
    "\n",
    "reviews_with_emoji_desc = [emoji.demojize(text) for text in new_texts]\n",
    "new_encodings = tokenizer(reviews_with_emoji_desc, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "\n",
    "# Run the model for inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "new_encodings = {key: val.to(device) for key, val in new_encodings.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**new_encodings)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Convert predictions to sentiment labels\n",
    "predicted_labels = ['positive' if pred == 1 else 'negative' for pred in predictions]\n",
    "\n",
    "# Display the results\n",
    "for text, label in zip(reviews_with_emoji_desc, predicted_labels):\n",
    "    print(f\"Text: \\\"{text}\\\"\")\n",
    "    print(f\"Predicted sentiment: {label}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train_texts and train_labels to lists, so they can be modified\n",
    "train_texts = list(train_texts)\n",
    "train_labels = list(train_labels)\n",
    "\n",
    "# Augment the dataset with negation examples\n",
    "negation_sentences = [\n",
    "    \"I am not happy with the service.\",\n",
    "    \"This is not what I expected.\",\n",
    "    \"The product didnâ€™t meet my expectations.\",\n",
    "    \"I don't like this at all.\",\n",
    "    \"The service wasnâ€™t good.\",\n",
    "]\n",
    "\n",
    "# Add these negation examples to your training data\n",
    "train_texts.extend(negation_sentences)\n",
    "train_labels.extend([0] * len(negation_sentences))  # Assign negative labels (0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the dataset with mixed sentiment examples\n",
    "mixed_sentiment_sentences = [\n",
    "    \"The product works well, but the customer support is terrible.\",\n",
    "    \"I loved the design, but the material is cheap.\",\n",
    "    \"Great functionality, but too expensive.\",\n",
    "]\n",
    "\n",
    "# Add these mixed sentiment examples to your training data\n",
    "train_texts.extend(mixed_sentiment_sentences)\n",
    "train_labels.extend([0] * len(mixed_sentiment_sentences))  # Assign negative labels or label as mixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the dataset with slang examples\n",
    "slang_sentences = [\n",
    "    \"This product is dope!\",\n",
    "    \"The new feature is lit!\",\n",
    "    \"That song is fire!\",\n",
    "]\n",
    "\n",
    "# Add these slang examples to your training data\n",
    "train_texts.extend(slang_sentences)\n",
    "train_labels.extend([1] * len(slang_sentences))  # Assign positive labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train_texts and train_labels to lists if they are tuples\n",
    "train_texts = list(train_texts)\n",
    "train_labels = list(train_labels)\n",
    "\n",
    "# Augment the dataset with sarcastic reviews\n",
    "sarcastic_reviews = [\n",
    "    \"Oh wow, this is the best product ever... not!\",  # Positive-sounding, but negative sentiment\n",
    "    \"Just what I needed, a broken item!\",            # Ironic, implying dissatisfaction\n",
    "    \"Yeah, because everyone loves waiting 2 weeks for a delivery...\",  # Sarcastic negative review\n",
    "    \"Oh great, it stopped working after one use. Fantastic.\",  # Sarcasm\n",
    "    \"Sure, this product is amazing if you like wasting money.\",  # Sarcastic and negative\n",
    "    \"Wow, I'm so impressed that it broke the second I touched it.\",  # Sarcasm\n",
    "]\n",
    "\n",
    "# Add these sarcastic examples to your training data\n",
    "train_texts.extend(sarcastic_reviews)\n",
    "train_labels.extend([0] * len(sarcastic_reviews))  # Assign negative labels (0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emojis_to_text(text):\n",
    "    return emoji.demojize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added sarcastic reviews with emojis converted to text:\n",
      "Review: Oh wow, this product is amazing... :face_with_tears_of_joy:, Label: 0\n",
      "Review: Love how it broke in one day :face_with_tears_of_joy:, Label: 0\n",
      "Review: Best service ever... not! :smiling_face_with_smiling_eyes:, Label: 0\n",
      "Review: Yeah, because everyone loves a broken item :smiling_face_with_heart-eyes:, Label: 0\n",
      "Review: Just fantastic, it stopped working immediately :grinning_face_with_smiling_eyes:, Label: 0\n",
      "Review: This is the best waste of money I've ever had :smiling_face_with_smiling_eyes:, Label: 0\n",
      "Review: I'm so impressed with how terrible this is :face_with_tears_of_joy:, Label: 0\n"
     ]
    }
   ],
   "source": [
    "sarcastic_reviews_with_positive_emojis = [\n",
    "    \"Oh wow, this product is amazing... ðŸ˜‚\",        # Sarcastic with laughing emoji\n",
    "    \"Love how it broke in one day ðŸ˜‚\",              # Sarcastic with laughing emoji\n",
    "    \"Best service ever... not! ðŸ˜Š\",                 # Sarcastic with smiling emoji\n",
    "    \"Yeah, because everyone loves a broken item ðŸ˜\", # Sarcastic with heart-eyes emoji\n",
    "    \"Just fantastic, it stopped working immediately ðŸ˜„\", # Sarcastic with happy emoji\n",
    "    \"This is the best waste of money I've ever had ðŸ˜Š\", # Sarcastic with smiling emoji\n",
    "    \"I'm so impressed with how terrible this is ðŸ˜‚\", # Sarcastic with laughing emoji\n",
    "]\n",
    "\n",
    "# Convert emojis to their text descriptions\n",
    "sarcastic_reviews_with_converted_emojis = [convert_emojis_to_text(review) for review in sarcastic_reviews_with_positive_emojis]\n",
    "\n",
    "# Add these converted sarcastic examples to your training data\n",
    "train_texts.extend(sarcastic_reviews_with_converted_emojis)\n",
    "train_labels.extend([0] * len(sarcastic_reviews_with_converted_emojis))  # Assign negative labels (0)\n",
    "\n",
    "# Print out the sarcastic examples with converted emojis\n",
    "print(\"Added sarcastic reviews with emojis converted to text:\")\n",
    "for text, label in zip(sarcastic_reviews_with_converted_emojis, [0] * len(sarcastic_reviews_with_converted_emojis)):\n",
    "    print(f\"Review: {text}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Load the saved model\n",
    "model = BertForSequenceClassification.from_pretrained('./bert_sentiment_model_v1')\n",
    "\n",
    "# Load the saved tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert_sentiment_model_v1')\n",
    "\n",
    "# Move the model to the appropriate device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amey9\\AppData\\Local\\Temp\\ipykernel_6664\\1151776240.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 155/155 [13:22<00:00,  5.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss with class weighting: 0.0303\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 155/155 [13:43<00:00,  5.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss with class weighting: 0.0133\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 155/155 [12:57<00:00,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss with class weighting: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW  # Use the PyTorch AdamW optimizer\n",
    "\n",
    "# Tokenize the expanded dataset\n",
    "train_encodings = tokenizer(train_texts, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "\n",
    "# Convert labels to tensor\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n",
    "# PyTorch Dataset class to handle tokenized encodings and labels\n",
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Fixed the issue here\n",
    "        return item\n",
    "\n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "train_dataset = ReviewDataset(train_encodings, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Compute class weights if the dataset is imbalanced\n",
    "classes = torch.unique(train_labels).numpy()  # [0, 1]\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=train_labels.numpy())\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Define the optimizer with PyTorch's AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training function with class weighting\n",
    "def train(model, train_loader, optimizer, device, class_weights):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        # Move inputs and labels to device (GPU or CPU)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass to get model outputs and calculate loss\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Apply class weights to the loss\n",
    "        weighted_loss = loss * class_weights[labels]\n",
    "        loss = weighted_loss.mean()  # Compute average loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        loss.backward()        # Backpropagation\n",
    "        optimizer.step()       # Update model parameters\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Average training loss with class weighting: {avg_loss:.4f}\")\n",
    "\n",
    "# Fine-tune for a few epochs\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    train(model, train_loader, optimizer, device, class_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bert_sentiment_tokenizer_v2\\\\tokenizer_config.json',\n",
       " './bert_sentiment_tokenizer_v2\\\\special_tokens_map.json',\n",
       " './bert_sentiment_tokenizer_v2\\\\vocab.txt',\n",
       " './bert_sentiment_tokenizer_v2\\\\added_tokens.json')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained('./bert_sentiment_v2')\n",
    "tokenizer.save_pretrained('./bert_sentiment_tokenizer_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = BertForSequenceClassification.from_pretrained('./bert_sentiment_v2')\n",
    "model.to(device)  # Move model to GPU or CPU\n",
    "\n",
    "# Load the saved tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert_sentiment_tokenizer_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9577\n",
      "F1 Score: 0.9775474956822107\n",
      "Confusion Matrix:\n",
      " [[ 11   9]\n",
      " [  4 283]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.55      0.63        20\n",
      "           1       0.97      0.99      0.98       287\n",
      "\n",
      "    accuracy                           0.96       307\n",
      "   macro avg       0.85      0.77      0.80       307\n",
      "weighted avg       0.95      0.96      0.95       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the test data\n",
    "test_encodings = tokenizer(test_texts, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Fixed the issue here\n",
    "        return item\n",
    "\n",
    "# Create test dataset and loader\n",
    "test_dataset = ReviewDataset(test_encodings, test_labels)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Move model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on test data\n",
    "correct = 0\n",
    "total = 0\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        label_ids = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        correct += (preds == label_ids).sum().item()\n",
    "        total += label_ids.size(0)\n",
    "        \n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        labels.extend(label_ids.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Optionally, calculate F1 score, precision, recall, confusion matrix\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"F1 Score:\", f1_score(labels, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(labels, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
